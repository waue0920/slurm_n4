#!/bin/bash
#SBATCH -A GOV115010  ## !! 更換成自己的計劃代號 !! 
#SBATCH --job-name=check_8n8g_gpu       ## 工作名稱
#SBATCH --output=slurm_script_20260202_061500.log ## 標準輸出與錯誤輸出同時記錄到此檔案
#SBATCH --error=slurm_script_20260202_061500.log  ## 標準錯誤輸出記錄同一檔案
#SBATCH --nodes=8                 ## 請求 8 個節點
#SBATCH --gres=gpu:8              ## 每個節點請求 8 張 GPU
#SBATCH --cpus-per-task=4         ## 單個任務請求 4 個 CPU
#SBATCH --partition=h200         ## 測試分區

# 載入必要的模組 (根據叢集需求)
module purge

# 開始記錄
echo "==============================="
echo "1. 節點資訊"
echo "目前執行節點: $(hostname)"

echo "==============================="
echo "2. GPU 數量"
nvidia-smi --list-gpus

echo "==============================="
echo "3. SLURM 系統參數"
scontrol show job $SLURM_JOB_ID

echo "==============================="
echo "4. SLURM Nodes"
echo "Allocated Nodes: $SLURM_JOB_NODELIST"

echo "==============================="
echo "5. SLURM 環境參數"
env | grep SLURM

echo "==============================="
echo "檢查完成！"
