#!/bin/bash
#SBATCH -J Torchrun                   # Job name
#SBATCH -o slurm-%j.out        # Name of stdout output file (%j expands to jobId)
#SBATCH --account="GOV109016"        # iService Project id
#SBATCH --nodes=2                  # Number of nodes
#SBATCH --gres=gpu:2               # Number of GPUs per node
#SBATCH --partition=gtest          # gtest,gp1d, gp2d, gp4d

## user parameter
#SIF=/home/waue0920/slurm/pytorch_22.01-py3.sif
SIF=/home/waue0920/slurm/pytorch_22.12-py3.sif
#PTH_FILE="/home/waue0920/slurm/run3/env.py"


GPUS_PER_NODE=$(nvidia-smi --query-gpu=name --format=csv,noheader |wc -l)
NNODES=${SLURM_JOB_NUM_NODES}
MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)
MASTER_PORT=$(shuf -i 60000-65530 -n 1)

TORCH_RUN="torchrun --nproc_per_node $GPUS_PER_NODE --nnodes $NNODES --master_addr $MASTER_ADDR --master_port $MASTER_PORT"
#PTH_FILE="train.py --batch_size 128 --epochs 5 --lr 0.01"
PTH_FILE="env.py"

## main start
# ml load
module purge
module load singularity

SINGULARITY="singularity run --nv $SIF"

# 將節點名稱拆分為串列
IFS=',' read -ra NODES <<< "${SLURM_NODELIST}"
# 排序節點
sorted_nodes=($(echo "${NODES[@]}" | tr ' ' '\n' | sort | tr '\n' ' '))

echo $sorted_nodes >> sorted_nodes.log
# 判斷節點順序並執行相應的命令
# 使用 for 迴圈依序執行 torchrun 命令
for ((i=0; i<${#sorted_nodes[@]}; i++)); do
    if [[ "${sorted_nodes[$i]}" == "$HOSTNAME" ]]; then
        srun $SINGULARITY --mpi=pmix $TORCH_RUN --node_rank $i $PTH_FILE
        break  # 執行完畢後中斷迴圈
    fi
done

#echo "srun --mpi=pmix $SINGULARITY $TORCH_RUN --node_rank $node_rank $PTH_FILE" >> slurm_srun.out
#srun $SINGULARITY --mpi=pmix $TORCH_RUN --node_rank $node_rank  $PTH_FILE
