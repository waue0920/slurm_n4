# H200 叢集大規模壓力測試：程序同步空轉 (Sync Stall) 事件分析報告

## 1. 測試事件與重現步驟 (Timeline & Reproduction)
本次分析記錄了 H200 叢集在執行 8 節點 (64 GPU) 極限負載測試時，於結束收尾階段發生的「程序卡住空轉」現象。

### 如何重現此現象 (Reproduction Steps)
1.  **規模要求**：必須在 8 節點以上（跨節點分散式環境）執行。
2.  **負載要求**：執行包含大量 GPU 運算 (GEMM) 與網路通訊 (NCCL) 的高強度壓力測試。
3.  **觸發時機**：持續運行 20~30 分鐘，直到測試步入最後的「全叢集數據彙整 (Final All-reduce)」與「WandB 同步收尾」階段。
4.  **觀測現象**：此時會發現 Log 停止更新，作業無法自動結束。

### 事件紀錄時間軸
| 時間 | 作業 ID | 事件描述 | 觀測現象 |
| :--- | :--- | :--- | :--- |
| **10:26** | **Job 530** | 啟動 30 分鐘 64-GPU 測試。 | 於 1778.9s 進入「程序空轉狀態」。 |
| **13:21** | **Job 540** | 啟動 20 分鐘 64-GPU 測試（加入心跳監控）。 | 跑完 220 圈後，於結尾彙整處再次進入「空轉狀態」。 |
| **13:45** | **Job 540** | **執行 SSH 實測診斷** | **srun 阻塞，但 SSH 可連入取證**。 |
| **13:50** | **Job 540** | 取得證據 | 程序同步空轉 (futex_wait)。 |

## 2. 故障現象與證據比對 (Evidences)
我們透過 Job 540 的現場取證，定義了如何區分「系統崩潰」與「程序空轉」：

### 關鍵特徵：管理與系統通道的響應背離
*   **srun 指令阻塞**：透過 Slurm 管理工具對掛死作業下達指令（如 `srun --jobid=540 ps`）時，指令會完全卡住不回傳。
*   **SSH 登入正常**：與此同時，直接透過 **`ssh` 登入** 節點 `25a-hgpn206` 卻非常流暢，且 `ls`, `ps` 等系統指令反應即時。
*   **結論**：這證實了這不是硬體或儲存系統的「死機」，而是 Slurm 管轄下的**應用程式層級同步空轉**。

### 證據二：進程持續佔用資源 (R 狀態) 但無法結束
*   **現象**：進入空轉狀態後，從系統 (`top`, `ps`) 觀察，絕大部分進程仍維持在 **`R` (Running)** 狀態。
*   **影響**：這代表程式雖然已無實質進度，但 CPU 核心仍被 100% 佔用進行忙碌輪詢（Busy-polling）。這會導致作業無法自動完成退場並釋放資源，直到達到 Walltime 上限或被手動取消為止，造成運算資源與電力無意義的損耗。

## 3. 根本原因診斷：活體取證分析
針對 Job 540 空轉現場的 SSH 偵查結果：

### 終端機實測紀錄
```bash
(base) [waue0920@25a-hgpn206 ~]$ ps -p 3905310 -o pid,state,wchan:30,cmd
    PID S WCHAN                          CMD
3905310 S futex_wait_queue               /home/waue0920/miniconda3/envs/fl_gyolo/bin/python3.10 -u ./stress_test_v2.py ...
```

1.  **進程分布**：
    *   在 Master 節點上的 8 個進程中，7 個處於 `R` (Running) 忙碌輪詢，僅 1 個 (PID 3905310) 處於 `S` (Sleep)。
2.  **核心障礙：終止信號漂移 (Termination Signal Drift)**：
    *   **代碼缺陷**：原腳本使用 `while time.time() - start_time < duration` 作為結束判準。在 64-GPU 叢集中，各節點本地時鐘的極微小偏差導致部分 Rank 決定退出，而其他 Rank 決定多跑一圈。
    *   **死鎖結果**：Rank 0 進入結尾彙整 (Barrier)，其餘結點卻在等下一圈的中間彙整。這導致了觀察到的 **`futex_wait_queue`**（一個進程等鎖，其餘進程 R 狀態空轉）現象。
3.  **診斷定調**：
    本次事件是由 **「高負載引發的系統抖動」** 與 **「分散式同步邏輯漏洞」** 共同交織而成的經典軟體工程錯誤。

## 4. 最終結論與優化方針

### 核心結論
本方案實證顯示，H200 叢集的硬體與 NFS 儲存體在基礎面是穩定的。目前的「程序卡住空轉」是**大規模平行運算中的同步機制弱點**。當 64 張顯卡在長期高壓後試圖進行最後一次握手時，極易因資源競爭導致其中一個進程進入等待鎖的狀態，進而引發整批作業的空轉。

### 改進建議
1.  **NCCL 防災設定**：在環境變數中加入 `NCCL_IB_TIMEOUT=22` 與 `NCCL_ASYNC_ERROR_HANDLING=1`，增加系統對「收尾抖動」的容忍度。
2.  **實施中間落地機制**：本次測試在程序卡住前已成功完成並儲存了 20 分鐘的 CSV 數據。**這證明「中間報表」是應對大規模叢集不可預知空轉的最佳策略。**
